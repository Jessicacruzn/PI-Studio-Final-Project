---
title: "Yelp Dataset Shortened"
author: "Dayvonn Jones"
date: "4/27/2022"
output: html_document
---

#Library Set Up#
```{r}
library(tidyverse)
library(ggplot2)
library(tidytext)
library(syuzhet)
library(esquisse)
rm(list = ls())
```
#Data Set Up
```{r}
setwd("~/PI Studio/PI-Studio-Final-Project/Dataset")
yelp_reviews <- read_csv('cleaned_dataframe.csv')
sentiment <- read_csv('df_median.csv')
```

#Bar Chart for Restaurants Open#
```{r}
restaurant_data <- yelp_reviews %>%
  distinct(business_id, .keep_all = TRUE)

open_v_closed <- restaurant_data %>%
  ggplot(aes(factor(x=is_open))) +
  scale_x_discrete(labels = c('Closed','Open')) +
  geom_bar() + 
  geom_text(stat="count",aes(label = ..count..), vjust = -0.5) +
  ggtitle('Amount of Restaurants Open vs. Closed in Dataset') +
  xlab('') +
  ylab('') +
  theme_minimal()
ggsave('OpenVClosed.jpeg', open_v_closed)
```

```{r}

ovc_state <- restaurant_data %>%
  group_by(state) %>%
  count(is_open )%>%
  ggplot(aes(fill=factor(is_open), y=n, x=state)) + 
  geom_bar(position="stack", stat="identity") +
  ggtitle('Amount of Restaurants In Each State That Are Open vs. Closed') +
  xlab('State') +
  ylab('Amount') +
  labs(fill='Status') +
  scale_fill_discrete(labels = c('Closed','Open')) +
  theme_minimal()

ggsave('OvC_each_state.jpeg', ovc_state)

```


#Bar Chart for Restaurants in States#
```{r}
esquisser(restaurant_data)
each_state <- ggplot(restaurant_data, aes(x= forcats::fct_infreq(state))) + 
  geom_bar() + 
  geom_text(stat="count",aes(label = ..count..), vjust = -0.5) +
  ggtitle('Amount of Restaurants In Each State From Dataset') +
  xlab('State') +
  ylab('') +
  theme_minimal()
ggsave('StateRestaurant.jpeg', each_state)
```

#Analyze
```{r}
library(tidyverse)
library(tidytext)
library(rtweet)
library(quanteda)
library(quanteda.textplots)
library(jsonlite)
library(sentimentr)
library(dplyr)
library(ggplot2)
library(textclean)
library(tm)
library(syuzhet)
library(NLP)
library(wordcloud)
library(RColorBrewer)
library(SnowballC)
library(textdata)
```

#The Reviews Ran for the First Time#
```{r}
yelp_reviews$text <- str_to_lower(yelp_reviews$text)
```

#Set Up Phrases#
```{r}
# colnames(sentiment)
phrasesCorpus = Corpus(VectorSource(yelp_reviews$text))
phrasesCorpus[[1]][1]
```
#Sentiment Set Up#
```{r}
emotions <- get_nrc_sentiment(yelp_reviews$text)
emotion_bar <- colSums(emotions)
emotion_sum <-data.frame(count=emotion_bar, emotion=names(emotion_bar))
```

#Bar Plot Showing the Count for 8 Different Emotions and the Negative and Positive Rating#
```{r}
ggplot(emotion_sum, aes(x = reorder(emotion, -count), y = count)) + 
  geom_bar(stat = 'identity') +
  labs(y = "Count of Emotion", x = NULL) + 
  coord_flip()
ggsave("emotion_sum.jpeg")
```

#Sentiment Analysis with the "tidytext" Package Using the "bing" lexicon#
```{r}
bing_word_counts <- yelp_reviews %>% unnest_tokens(output = word, input = text) %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE)
```

#Select Top 10 Words by Sentiment#
```{r}
bing_top_10_words_by_sentiment <- bing_word_counts %>% 
  group_by(sentiment) %>% 
  slice_max(order_by = n, n = 10) %>% 
  ungroup() %>% 
  mutate(word = reorder(word, n)) 
bing_top_10_words_by_sentiment
```

#Create a Bar Plot Showing the Contribution of Words to the Sentiment#
```{r}
bing_top_10_words_by_sentiment %>% 
  ggplot(aes(word, n, fill = sentiment)) + 
  geom_col(show.legend = FALSE) + 
  facet_wrap(~sentiment, scales = "free_y") + 
  labs(y = "Contribution to Sentiment Words", x = NULL) + 
  coord_flip()
ggsave("contribution_to_sentiment_words.jpeg")
```
#Sentiment Analysis with the "tidytext" Package using the "loughran" lexicon#
```{r}
loughran_word_counts <- yelp_reviews %>% unnest_tokens(output = word, input = text) %>%
  inner_join(get_sentiments("loughran")) %>%
  count(word, sentiment, sort = TRUE)
```
#Selecting the Top 10 Words by the Sentiment#
```{r}
loughran_top_10_words_by_sentiment <- loughran_word_counts %>% 
  group_by(sentiment) %>% 
  slice_max(order_by = n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n))
loughran_top_10_words_by_sentiment
```

#Creating a Bar Plot Showing Contribution of Words to the Sentiment#
```{r}
loughran_top_10_words_by_sentiment %>% 
  ggplot(aes(word, n, fill = sentiment)) + 
  geom_col(show.legend = FALSE) + 
  facet_wrap(~sentiment, scales = "free_y") + 
  labs(y = "Contribution to sentiment", x = NULL) + 
  coord_flip()
#ggsave("contribution_to_sentiment.jpeg")
```

#Set Up Wordcloud#
```{r}
phrasesCorpus = tm_map(phrasesCorpus, content_transformer(tolower))
phrasesCorpus = tm_map(phrasesCorpus, removeNumbers)
phrasesCorpus = tm_map(phrasesCorpus, PlainTextDocument)
phrasesCorpus = tm_map(phrasesCorpus, removePunctuation)
phrasesCorpus = tm_map(phrasesCorpus, removeWords, stopwords("english"))
phrasesCorpus = tm_map(phrasesCorpus, stemDocument)
#phrasesCorpus = tm_map(phrasesCorpus, stripWhitespace)
phrasesCorpus <- Corpus(VectorSource(phrasesCorpus))
phrasesCorpus[[1]][1]
```

#Create TDM#
```{r}
myDTM = DocumentTermMatrix(phrasesCorpus)
m = as.matrix(myDTM)
v = sort(rowSums(m), decreasing = TRUE)
d = data.frame(word = names(v),freq=v)
```

#Wordcloud#
```{r}
wordcloud(d$word, d$freq, random.order=FALSE, rot.per=0.35, scale=c(5,0.5), max.words=100, colors=brewer.pal(8, "Dark2") )
```

```{r}
open <- yelp_reviews %>%
  filter(is_open == 1) %>%
  mutate(
    is_open = 'Open',
    text = str_remove_all(text, "&amp;")
  )
open <- subset(open, select = c(is_open, text))

closed <- yelp_reviews %>%
  filter(is_open == 0) %>%
  mutate(
    is_open = 'Closed',
    text = str_remove_all(text, "&amp;")
  )
closed <- subset(closed, select = c(is_open, text))

corp_tl <- rbind(open %>% select(text, is_open), closed %>% select(text, is_open))
corp <- corpus(corp_tl, text_field = "text")

corp %>%
  tokens(remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %>%
  tokens_remove(stopwords("english")) %>%
  dfm() %>%
  dfm_group(groups = is_open) %>%
  dfm_trim(min_termfreq = 50, verbose = FALSE) %>%
  textplot_wordcloud(comparison = TRUE, color = c("red", "blue"))
```


